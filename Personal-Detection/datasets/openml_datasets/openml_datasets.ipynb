{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect datasets based on real-world data, that are personal related  \n",
    "Search for specific personal-related categories (credit-card, insurance ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import openml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Name: CSM\n",
      "Description: Conventional and Social Media Movies (CSM) - Dataset 2014 and 2015 Data Set\n",
      "\n",
      "\n",
      "\n",
      "12 features categorized as conventional and social media features. Both conventional features, collected from movies databases on Web as well as social media features(YouTube,Twitter).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Gross</th>\n",
       "      <th>Budget</th>\n",
       "      <th>Screens</th>\n",
       "      <th>Sequel</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Views</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Dislikes</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Aggregate.Followers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>8</td>\n",
       "      <td>9130.0</td>\n",
       "      <td>4000000.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3280543.0</td>\n",
       "      <td>4632.0</td>\n",
       "      <td>425.0</td>\n",
       "      <td>636.0</td>\n",
       "      <td>1120000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>1</td>\n",
       "      <td>192000000.0</td>\n",
       "      <td>50000000.0</td>\n",
       "      <td>3306.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>583289.0</td>\n",
       "      <td>3465.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>12350000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>1</td>\n",
       "      <td>30700000.0</td>\n",
       "      <td>28000000.0</td>\n",
       "      <td>2872.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>304861.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>483000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1</td>\n",
       "      <td>106000000.0</td>\n",
       "      <td>110000000.0</td>\n",
       "      <td>3470.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>452917.0</td>\n",
       "      <td>2429.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>590.0</td>\n",
       "      <td>568000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>8</td>\n",
       "      <td>17300000.0</td>\n",
       "      <td>3500000.0</td>\n",
       "      <td>2310.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3145573.0</td>\n",
       "      <td>12163.0</td>\n",
       "      <td>610.0</td>\n",
       "      <td>1082.0</td>\n",
       "      <td>1923800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>2015.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>4</td>\n",
       "      <td>1210000.0</td>\n",
       "      <td>50000000.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3701061.0</td>\n",
       "      <td>9325.0</td>\n",
       "      <td>641.0</td>\n",
       "      <td>1859.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>2015.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>15</td>\n",
       "      <td>21000000.0</td>\n",
       "      <td>37000000.0</td>\n",
       "      <td>2815.0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7119456.0</td>\n",
       "      <td>18803.0</td>\n",
       "      <td>1128.0</td>\n",
       "      <td>2290.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>2015.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>8</td>\n",
       "      <td>10200000.0</td>\n",
       "      <td>35000000.0</td>\n",
       "      <td>2777.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3450614.0</td>\n",
       "      <td>6823.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>409.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>2015.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>1</td>\n",
       "      <td>12300000.0</td>\n",
       "      <td>3000000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>66872.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>2015.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>15</td>\n",
       "      <td>22600000.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>2720.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>659772.0</td>\n",
       "      <td>2841.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>606.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>231 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year  Ratings  Genre        Gross       Budget  Screens  Sequel  \\\n",
       "0    2014.0      6.3      8       9130.0    4000000.0     45.0       1   \n",
       "1    2014.0      7.1      1  192000000.0   50000000.0   3306.0       2   \n",
       "2    2014.0      6.2      1   30700000.0   28000000.0   2872.0       1   \n",
       "3    2014.0      6.3      1  106000000.0  110000000.0   3470.0       2   \n",
       "4    2014.0      4.7      8   17300000.0    3500000.0   2310.0       2   \n",
       "..      ...      ...    ...          ...          ...      ...     ...   \n",
       "226  2015.0      6.4      4    1210000.0   50000000.0     66.0       1   \n",
       "227  2015.0      5.5     15   21000000.0   37000000.0   2815.0       1   \n",
       "228  2015.0      5.4      8   10200000.0   35000000.0   2777.0       1   \n",
       "229  2015.0      5.4      1   12300000.0    3000000.0      NaN       1   \n",
       "230  2015.0      4.4     15   22600000.0     100000.0   2720.0       1   \n",
       "\n",
       "     Sentiment      Views    Likes  Dislikes  Comments  Aggregate.Followers  \n",
       "0          0.0  3280543.0   4632.0     425.0     636.0            1120000.0  \n",
       "1          2.0   583289.0   3465.0      61.0     186.0           12350000.0  \n",
       "2          0.0   304861.0    328.0      34.0      47.0             483000.0  \n",
       "3          0.0   452917.0   2429.0     132.0     590.0             568000.0  \n",
       "4          0.0  3145573.0  12163.0     610.0    1082.0            1923800.0  \n",
       "..         ...        ...      ...       ...       ...                  ...  \n",
       "226        4.0  3701061.0   9325.0     641.0    1859.0                  NaN  \n",
       "227       13.0  7119456.0  18803.0    1128.0    2290.0                  NaN  \n",
       "228        7.0  3450614.0   6823.0     325.0     409.0                  NaN  \n",
       "229       10.0    66872.0    400.0      67.0     201.0                  NaN  \n",
       "230       -5.0   659772.0   2841.0     431.0     606.0                  NaN  \n",
       "\n",
       "[231 rows x 13 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = openml.datasets.get_dataset(42371)\n",
    "name = str(dataset.name)\n",
    "X, y, _, _ = dataset.get_data()\n",
    "print(\"Dataset Name: \" + name)\n",
    "print(\"Description: \"+ dataset.description)\n",
    "pd.concat([X, y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [45929, 46105, 46103, 46087, 43743,       #personal data\n",
    "       46382, 46381, 46351, 45934, 42371]               #non-personal data\n",
    "for id in ids:\n",
    "    dataset = openml.datasets.get_dataset(id)\n",
    "    name = str(dataset.name)\n",
    "    os.makedirs(f\"{name}\", exist_ok=True)\n",
    "    X, y, _, _ = dataset.get_data()\n",
    "    pd.concat([X, y], axis=1).to_csv(f\"{name}/data.csv\", index=False)\n",
    "    metadata_dict = {\"Dataset Name: \" : name,\n",
    "                     \"Description: \": str(dataset.description),\n",
    "                     \"Features: \": str(list(dataset.features.values()))\n",
    "                     }\n",
    "    with open(f\"{name}/metadata.json\", 'w') as file:\n",
    "        json.dump(metadata_dict, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "automatically label the column as personal-related if it is from the first ten datasets       \n",
    "Personal-related is in this context data that can be used in combination with other data to identify a person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luca\\AppData\\Local\\Temp\\ipykernel_16512\\4156809596.py:6: DtypeWarning: Columns (9,12,13,14,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path + \"/\" + csv_file)\n"
     ]
    }
   ],
   "source": [
    "def create_json_labels_personal():\n",
    "    folders = [name for name in os.listdir(\".\") if os.path.isdir(os.path.join(\".\", name))]\n",
    "    for folder in folders:\n",
    "        path =  folder\n",
    "        csv_file = \"/data.csv\"\n",
    "        df = pd.read_csv(path + \"/\" + csv_file)\n",
    "        columns_personal = dict()\n",
    "        #first label everything as personal automatically and then relabel them afterwards manually in the json file\n",
    "        if folder in [\"Amazon_Prime_Fiction\", \"DATASETBANK\", \"FitBit_HeartRate\", \"TVS_Loan_Default\", \"Oilst_Customers_Dataset\"]:\n",
    "            lab = \"personal\"  \n",
    "        else:\n",
    "            lab = \"non-personal\"            \n",
    "        for c in df.columns:\n",
    "            columns_personal[c] = lab\n",
    "        columns_personal[\"overall\"] = lab\n",
    "        with open(f'{folder}/{csv_file}-labels_personal.json', 'w') as file:\n",
    "            json.dump(columns_personal, file, indent=4)\n",
    "            \n",
    "#line to execute function is commented so that it is not always executed, labeling process only happens once\n",
    "#create_json_labels_personal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SOME LABELS WERE ADJUSTED MANUALLY AFTERWARDS IN THE JSON FILES**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the labels into a suitable csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = [name for name in os.listdir(\".\") if os.path.isdir(os.path.join(\".\", name))]\n",
    "for folder in folders:\n",
    "    path_folder =  folder\n",
    "    csv_file = [f for f in os.listdir(path_folder) if f.endswith('.csv') and 'labels' not in f][0]\n",
    "    path = path_folder + \"/\" + csv_file + \"-labels_personal.json\"\n",
    "    with open(path, 'r') as file:\n",
    "        labels_json = json.load(file)\n",
    "    pd.DataFrame(labels_json, index=[0]).T.rename(columns={0: \"label\"}).to_csv(path_folder + \"/labels_personal.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate all datasets and labels for CASSED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luca\\AppData\\Local\\Temp\\ipykernel_12244\\2062023279.py:9: DtypeWarning: Columns (9,12,13,14,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_add = pd.read_csv(path_folder + \"/\" + csv_file)\n"
     ]
    }
   ],
   "source": [
    "folders = [name for name in os.listdir(\".\") if os.path.isdir(os.path.join(\".\", name))]\n",
    "all_dfs = pd.DataFrame()\n",
    "all_dfs_labels = pd.DataFrame()\n",
    "dataset_name = []\n",
    "for folder in folders:\n",
    "    path_folder =  folder\n",
    "    csv_file = [f for f in os.listdir(path_folder) if f.endswith('.csv') and 'labels' not in f][0]\n",
    "    csv_file_label = [f for f in os.listdir(path_folder) if f.endswith('.csv') and 'labels_personal' in f][0]\n",
    "    df_add = pd.read_csv(path_folder + \"/\" + csv_file)\n",
    "    all_dfs = pd.concat([all_dfs, df_add.iloc[:100,:]], axis = 1)\n",
    "    add_dfs_labels = pd.read_csv(path_folder + \"/\" + csv_file_label)\n",
    "    all_dfs_labels = pd.concat([all_dfs_labels, add_dfs_labels.iloc[:-1]]).reset_index(drop=True)\n",
    "    dataset_name += [folder] * df_add.shape[1]\n",
    "all_dfs.to_csv(\"all_datasets.csv\", index=False)\n",
    "all_dfs_labels.to_csv(\"all_datasets_labels_personal.csv\", index=False)\n",
    "pd.DataFrame(dataset_name).rename(columns={0: \"dataset\"}).to_csv(\"all_datasets_names.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PII"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "automatically label the column as pii if it only contains unique values  \n",
    "Afterwards look trough all .json files and check the column labeling      \n",
    "only columns which can contain personal identifiable information without a combination with other information are marked as pii "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luca\\AppData\\Local\\Temp\\ipykernel_37732\\2034111563.py:14: DtypeWarning: Columns (9,12,13,14,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path + \"/\" + csv_file, sep=sep)\n"
     ]
    }
   ],
   "source": [
    "def create_json_labels_pii():\n",
    "    folders = [name for name in os.listdir(\".\") if os.path.isdir(os.path.join(\".\", name))]\n",
    "    for folder in folders:\n",
    "        path =  folder\n",
    "        csv_file = [f for f in os.listdir(path) if f.endswith('.csv') and 'labels' not in f][0]\n",
    "        with open(path + \"/\" + csv_file, 'r') as file:\n",
    "            first_line = file.readline()\n",
    "            comma_count = first_line.count(',')\n",
    "            semicolon_count = first_line.count(';')\n",
    "            if comma_count > semicolon_count:\n",
    "                sep = \",\"\n",
    "            else:\n",
    "                sep = \";\"\n",
    "        df = pd.read_csv(path + \"/\" + csv_file, sep=sep)\n",
    "        columns_personal = dict()\n",
    "        for c in df.columns:\n",
    "            columns_personal[c] = \"non-pii\"\n",
    "        columns_personal[\"overall\"] = \"non-pii\"\n",
    "        with open(f'{folder}/{csv_file}-labels_pii.json', 'w') as file:\n",
    "            json.dump(columns_personal, file, indent=4)\n",
    "\n",
    "#line to execute function is commented so that it is not always executed, labeling process only happens once\n",
    "#create_json_labels_pii()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SOME LABELS WERE ADJUSTED MANUALLY AFTERWARDS IN THE JSON FILES**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the labels into a suitable csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = [name for name in os.listdir(\".\") if os.path.isdir(os.path.join(\".\", name))]\n",
    "for folder in folders:\n",
    "    path_folder =  folder\n",
    "    csv_file = [f for f in os.listdir(path_folder) if f.endswith('.csv') and 'labels' not in f][0]\n",
    "    path = path_folder + \"/\" + csv_file + \"-labels_pii.json\"\n",
    "    with open(path, 'r') as file:\n",
    "        labels_json = json.load(file)\n",
    "    pd.DataFrame(labels_json, index=[0]).T.rename(columns={0: \"label\"}).to_csv(path_folder + \"/labels_pii.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate all datasets and labels for CASSED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luca\\AppData\\Local\\Temp\\ipykernel_12244\\621536260.py:17: DtypeWarning: Columns (9,12,13,14,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_add = pd.read_csv(path_folder + \"/\" + csv_file, sep=sep)\n"
     ]
    }
   ],
   "source": [
    "folders = [name for name in os.listdir(\".\") if os.path.isdir(os.path.join(\".\", name))]\n",
    "all_dfs = pd.DataFrame()\n",
    "all_dfs_labels = pd.DataFrame()\n",
    "for folder in folders:\n",
    "    path_folder =  folder\n",
    "    csv_file = [f for f in os.listdir(path_folder) if f.endswith('.csv') and 'labels' not in f][0]\n",
    "    csv_file_label = [f for f in os.listdir(path_folder) if f.endswith('.csv') and 'labels_pii' in f][0]\n",
    "    \n",
    "    with open(path_folder + \"/\" + csv_file, 'r') as file:\n",
    "        first_line = file.readline()\n",
    "        comma_count = first_line.count(',')\n",
    "        semicolon_count = first_line.count(';')\n",
    "        if comma_count > semicolon_count:\n",
    "            sep = \",\"\n",
    "        else:\n",
    "            sep = \";\"\n",
    "    df_add = pd.read_csv(path_folder + \"/\" + csv_file, sep=sep)\n",
    "    \n",
    "    all_dfs = pd.concat([all_dfs, df_add.iloc[:100,:]], axis = 1)\n",
    "    add_dfs_labels = pd.read_csv(path_folder + \"/\" + csv_file_label)\n",
    "    all_dfs_labels = pd.concat([all_dfs_labels, add_dfs_labels.iloc[:-1]]).reset_index(drop=True)\n",
    "all_dfs.to_csv(\"all_datasets.csv\", index=False)\n",
    "all_dfs_labels.to_csv(\"all_datasets_labels_pii.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
