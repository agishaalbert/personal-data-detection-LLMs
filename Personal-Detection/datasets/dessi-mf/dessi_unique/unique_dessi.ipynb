{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reduce dessi dataset so that for every of the 20 classes are only unique values present"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dessi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_54535/1410128411.py:5: DtypeWarning: Columns (62,107,161,241,255,324,449,503,686,720,807,812,889,934,1073,1113,1133,1154,1158,1242,1317,1333,1394,1408,1470,1553,1577,1674,1729,1762,1872,1913,1940,2045,2131,2139,2209,2288,2404,2436,2601,2627,2663,2779,2841,2960,2994,3061,3063,3080,3129,3136,3250,3319,3439,3464,3499,3520,3596,3637,3649,3748,3778,3787,3808,3902,3907,3917,3951,4009,4034,4037,4069,4129,4210,4218,4252,4325,4359,4386,4479,4646,4649,4652,4710,4936,4939,5013,5065,5069,5348,5352,5356,5399,5476,5702,5736,5889,5962,6072,6094,6107,6140,6159,6337,6360,6383,6407,6415,6423,6507,6555,6567,6590,6593,6689,6809,6815,6920,6995,7042,7127,7163,7229,7295,7301,7319,7321,7354,7399,7403,7465,7474,7593,7594,7694,7719,7798,7872,7979,8179,8298,8308,8473,8542,8565,8568,8570,8579,8633,8662,8707,8835,8846,8859,8899,8933,9024,9084,9126,9170,9184,9198,9251,9329,9412,9505,9588,9592,9610,9652,9803,9818,9907,9908,9952,9975,10073,10099,10136,10161,10359,10369,10407,10427,10515,10589,10694,10748,10778,10787,10830,10839,10898,11026,11068,11201,11265,11326,11364,11372,11434,11475,11532,11559,11592,11618,11629,11649,11732,11770,11828,11886,11944,12014,12161,12240,12287,12385,12438,12508,12624,12673,12741,12843,12844,12897,12938,12977,13081,13099,13177,13195,13335,13373,13416,13437,13523,13621,13622,13671,13730,13746,13785,13914,14012,14048,14073,14126,14136,14140,14178,14204,14332,14507,14519,14525,14595,14614,14821,14828,14862,14920,14922,14948,15136,15151,15202,15250,15390,15401,15408,15442,15518,15640,15717,15781,15791,15811,15833,15858,15997,16055,16203,16211,16253,16254,16259,16277,16346,16418,16459,16517,16571,16644,16652,16731,16757,16769,16807,16845,16874,16880,16937,16993,17058,17116,17152,17256,17273,17280,17327,17362,17390,17472,17548,17602,17665,17678,17822,17882,17970,18032,18072,18096,18188,18245,18270,18351,18365,18428,18451,18455,18517,18529,18682,18721,18732,18738,18745) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train = pd.read_csv(\"../../dessi/DeSSI_v2/train.csv\")\n"
     ]
    }
   ],
   "source": [
    "labels_train = pd.read_csv(\"../../dessi/dessi_cleaned/train_labels.csv\")\n",
    "labels_dev = pd.read_csv(\"../../dessi/dessi_cleaned/dev_labels.csv\")\n",
    "labels_test = pd.read_csv(\"../../dessi/dessi_cleaned/test_labels.csv\")\n",
    "\n",
    "train = pd.read_csv(\"../../dessi/DeSSI_v2/train.csv\")\n",
    "dev = pd.read_csv(\"../../dessi/DeSSI_v2/dev.csv\")\n",
    "test = pd.read_csv(\"../../dessi/DeSSI_v2/test.csv\")\n",
    "\n",
    "dessi_all = pd.concat([train, dev, test], axis=1)\n",
    "dessi_all_labels = pd.concat([labels_train, labels_dev, labels_test])\n",
    "\n",
    "dessi_all_labels = dessi_all_labels.T\n",
    "dessi_all_labels.columns = dessi_all.columns\n",
    "dessi_all = pd.concat([dessi_all, dessi_all_labels],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dessi_unique_dict = dict()\n",
    "dessi_all.columns = np.arange(dessi_all.shape[1])       #necessary to make the column names unique\n",
    "for c in dessi_all.iloc[100,:].unique():\n",
    "    s = dessi_all.loc[100] == c\n",
    "    data = dessi_all.iloc[:100,:]\n",
    "    set_data = set(data[s.index[s==True].tolist()].values.flatten()) \n",
    "\n",
    "    if ',' not in c:\n",
    "        # Remove the values that appear in multilabel columns, as these values will be kept\n",
    "        s2 = (dessi_all.iloc[100,:].str.contains(c)) & (dessi_all.iloc[100,:] != c)\n",
    "        set_data_rem = set(data[s2.index[s2==True].tolist()].values.flatten()) \n",
    "        set_data = set_data - set_data_rem\n",
    "    set_data = set([str(a) for a in set_data])\n",
    "    dessi_unique_dict[c] = set_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phone_number 353649\n",
      "Other_data 323786\n",
      "NIN 167226\n",
      "Date 125718\n",
      "Geolocation 77218\n",
      "Phone_number,NIN 22487\n",
      "NIN,Date 22436\n",
      "NIN,Phone_number 21686\n",
      "SWIFT/BIC 21506\n",
      "Date,NIN 19854\n",
      "NIN,Person 17241\n",
      "NIN,Email 15676\n",
      "Person 15372\n",
      "Person,NIN 15016\n",
      "Phone_number,Email 14855\n",
      "Email,Phone_number 14132\n",
      "Email,NIN 13245\n",
      "Passport 10580\n",
      "Person,Organization 10172\n",
      "Organization,Person 10109\n",
      "Person,Email 10080\n",
      "Email,Person 9475\n",
      "IBAN 9425\n",
      "Email,Address 8837\n",
      "Address,Email 8457\n",
      "Address,Geolocation 7302\n",
      "Geolocation,Address 6839\n",
      "CCN 6372\n",
      "ID_Card 6016\n",
      "Organization 4973\n",
      "Address 4482\n",
      "GPE 3687\n",
      "Email 2098\n",
      "Nationality 453\n",
      "Address,Phone_number 400\n",
      "Address,Person,Phone_number 300\n",
      "Organization,Phone_number 300\n",
      "Organization,Address 200\n",
      "Person,Phone_number 200\n",
      "Religion 191\n",
      "Sexuality 184\n",
      "Gender 103\n",
      "Address,Person 100\n",
      "Person,Date 100\n",
      "Race 53\n"
     ]
    }
   ],
   "source": [
    "dessi_unique_dict = dict(sorted(dessi_unique_dict.items(), key=lambda item: len(item[1]), reverse=True))\n",
    "for keys, vals in dessi_unique_dict.items():\n",
    "    print(keys, len(vals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep all columns of classes with less than 1000 different values (exception columns with multi labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = []\n",
    "dessi_unique = pd.DataFrame()\n",
    "less_than_1000 = [\"Nationality\", \"Religion\", \"Gender\", \"Sexuality\", \"Race\"]\n",
    "for i in range(dessi_all.shape[1]):\n",
    "    if dessi_all.iloc[100,i] in less_than_1000:\n",
    "        keep.append(i)\n",
    "dessi_unique = dessi_all.iloc[:,keep]\n",
    "\n",
    "for key in dessi_unique_dict.keys():\n",
    "    if key in less_than_1000:\n",
    "        continue\n",
    "    \n",
    "    cols = np.floor(len(dessi_unique_dict[key]) / 100).astype(int).item()\n",
    "    values = sorted(dessi_unique_dict[key])[:cols*100]\n",
    "    random.shuffle(values)      #seed is set to 42 at the beginning of the notebook\n",
    "    add_df = pd.DataFrame(np.array(values).reshape(100, cols))\n",
    "    add_df = pd.concat([add_df, pd.DataFrame([key] * add_df.shape[1]).T] ).reset_index(drop=True)\n",
    "    dessi_unique = pd.concat([dessi_unique, add_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rename column names based on original column names of dessi dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_54535/1419497817.py:2: DtypeWarning: Columns (62,107,161,241,255,324,449,503,686,720,807,812,889,934,1073,1113,1133,1154,1158,1242,1317,1333,1394,1408,1470,1553,1577,1674,1729,1762,1872,1913,1940,2045,2131,2139,2209,2288,2404,2436,2601,2627,2663,2779,2841,2960,2994,3061,3063,3080,3129,3136,3250,3319,3439,3464,3499,3520,3596,3637,3649,3748,3778,3787,3808,3902,3907,3917,3951,4009,4034,4037,4069,4129,4210,4218,4252,4325,4359,4386,4479,4646,4649,4652,4710,4936,4939,5013,5065,5069,5348,5352,5356,5399,5476,5702,5736,5889,5962,6072,6094,6107,6140,6159,6337,6360,6383,6407,6415,6423,6507,6555,6567,6590,6593,6689,6809,6815,6920,6995,7042,7127,7163,7229,7295,7301,7319,7321,7354,7399,7403,7465,7474,7593,7594,7694,7719,7798,7872,7979,8179,8298,8308,8473,8542,8565,8568,8570,8579,8633,8662,8707,8835,8846,8859,8899,8933,9024,9084,9126,9170,9184,9198,9251,9329,9412,9505,9588,9592,9610,9652,9803,9818,9907,9908,9952,9975,10073,10099,10136,10161,10359,10369,10407,10427,10515,10589,10694,10748,10778,10787,10830,10839,10898,11026,11068,11201,11265,11326,11364,11372,11434,11475,11532,11559,11592,11618,11629,11649,11732,11770,11828,11886,11944,12014,12161,12240,12287,12385,12438,12508,12624,12673,12741,12843,12844,12897,12938,12977,13081,13099,13177,13195,13335,13373,13416,13437,13523,13621,13622,13671,13730,13746,13785,13914,14012,14048,14073,14126,14136,14140,14178,14204,14332,14507,14519,14525,14595,14614,14821,14828,14862,14920,14922,14948,15136,15151,15202,15250,15390,15401,15408,15442,15518,15640,15717,15781,15791,15811,15833,15858,15997,16055,16203,16211,16253,16254,16259,16277,16346,16418,16459,16517,16571,16644,16652,16731,16757,16769,16807,16845,16874,16880,16937,16993,17058,17116,17152,17256,17273,17280,17327,17362,17390,17472,17548,17602,17665,17678,17822,17882,17970,18032,18072,18096,18188,18245,18270,18351,18365,18428,18451,18455,18517,18529,18682,18721,18732,18738,18745) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  original_data = pd.read_csv(f\"../../dessi/DeSSI_v2/train.csv\")\n"
     ]
    }
   ],
   "source": [
    "#rename column names based on original column names of dessi dataset\n",
    "original_data = pd.read_csv(f\"../../dessi/DeSSI_v2/train.csv\")\n",
    "original_labels = pd.read_csv(f\"../../dessi/DeSSI_v2/train_labels.csv\")\n",
    "for split in [\"dev\", \"test\"]:\n",
    "    original_data = pd.concat([original_data, pd.read_csv(f\"../../dessi/DeSSI_v2/{split}.csv\")], axis=1)\n",
    "    original_labels = pd.concat([original_labels, pd.read_csv(f\"../../dessi/DeSSI_v2/{split}_labels.csv\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_other_columns_set(key):\n",
    "    vals = []\n",
    "    for (c, a) in columns_names.items():\n",
    "        if c == key:\n",
    "            continue\n",
    "        for b in a:\n",
    "            vals.append(b)\n",
    "    return set(vals)\n",
    "\n",
    "def generate_random_string(length):\n",
    "    characters = string.ascii_letters + string.digits\n",
    "    return ''.join(random.choice(characters) for _ in range(length))\n",
    "\n",
    "def rename_columns(data, columns_names):\n",
    "    labels = data.iloc[100,:].copy()\n",
    "    data_columns = list(data.columns.copy())\n",
    "    for i in range(data.shape[1]):\n",
    "        try:\n",
    "            data_columns[i] = columns_names[str(labels.iloc[i])].pop()\n",
    "        except IndexError:  # if there are not enough unique column names for a specific class\n",
    "            random_length = random.randint(5, 20)\n",
    "            random_string = generate_random_string(random_length)\n",
    "            data_columns[i] = random_string\n",
    "    data.columns = data_columns\n",
    "    return data\n",
    "\n",
    "columns_names = dict()\n",
    "for i in original_labels[\"label\"].unique():\n",
    "    columns_names[i] = set()\n",
    "for e, i in enumerate(original_labels[\"label\"]):\n",
    "    columns_names[i].add(original_data.columns[e])\n",
    "for i in original_labels[\"label\"].unique():\n",
    "    other_columns = get_other_columns_set(i)\n",
    "    columns_names[i] = columns_names[i] - other_columns\n",
    "    columns_names[i] = sorted(columns_names[i])\n",
    "    random.shuffle(columns_names[i]) \n",
    "for (key, sets) in columns_names.items():\n",
    "    columns_names[key] = sets\n",
    "\n",
    "dessi_unique = rename_columns(dessi_unique.copy(), columns_names.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (101, 8631)\n",
      "Validation data shape: (101, 2877)\n",
      "Test data shape: (101, 2878)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_54535/431264816.py:18: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  val_idx, test_idx = next(split2.split(temp_data.T, stratify_labels[temp_idx]))\n"
     ]
    }
   ],
   "source": [
    "shuffled_data = dessi_unique.sample(frac=1, axis=1, random_state=42)\n",
    "stratify_labels = shuffled_data.iloc[100, :]\n",
    "no_splitting = []\n",
    "ser = stratify_labels.value_counts() <= 4\n",
    "for i in range(shuffled_data.shape[1]):\n",
    "    if shuffled_data.iloc[100,i] in ser[ser == True].index:\n",
    "        no_splitting.append(i)\n",
    "no_splitting_df = shuffled_data.iloc[:, no_splitting]\n",
    "shuffled_data = shuffled_data.iloc[:, [a for a in range(shuffled_data.shape[1]) if a not in no_splitting]]\n",
    "stratify_labels = shuffled_data.iloc[100, :]\n",
    "\n",
    "split1 = StratifiedShuffleSplit(n_splits=1, test_size=0.4, random_state=42)\n",
    "train_idx, temp_idx = next(split1.split(shuffled_data.T, stratify_labels))\n",
    "train_data = shuffled_data.iloc[:, train_idx]\n",
    "temp_data = shuffled_data.iloc[:, temp_idx]  \n",
    "\n",
    "split2 = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=42)\n",
    "val_idx, test_idx = next(split2.split(temp_data.T, stratify_labels[temp_idx]))\n",
    "\n",
    "val_data = temp_data.iloc[:, val_idx] \n",
    "test_data = temp_data.iloc[:, test_idx]\n",
    "\n",
    "train_add, temp_add = train_test_split(no_splitting_df.T, test_size=0.4, random_state=42)\n",
    "val_add, test_add = train_test_split(temp_add, test_size=0.5, random_state=42)\n",
    "\n",
    "train_data = pd.concat([train_data, train_add.T], axis=1)\n",
    "val_data = pd.concat([val_data, val_add.T], axis=1)\n",
    "test_data = pd.concat([test_data, test_add.T], axis=1)\n",
    "\n",
    "print(\"Train data shape:\", train_data.shape)\n",
    "print(\"Validation data shape:\", val_data.shape)\n",
    "print(\"Test data shape:\", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.iloc[:100,:].to_csv(\"train.csv\", index=False)\n",
    "val_data.iloc[:100,:].to_csv(\"dev.csv\", index=False)\n",
    "test_data.iloc[:100,:].to_csv(\"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(train_data.iloc[100,:]).rename(columns={100: \"label\"}).to_csv(\"train_labels.csv\", index=False)\n",
    "pd.DataFrame(val_data.iloc[100,:]).rename(columns={100: \"label\"}).to_csv(\"dev_labels.csv\", index=False)\n",
    "pd.DataFrame(test_data.iloc[100,:]).rename(columns={100: \"label\"}).to_csv(\"test_labels.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
