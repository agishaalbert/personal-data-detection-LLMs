{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from faker import Faker\n",
    "from sklearn.model_selection  import StratifiedShuffleSplit\n",
    "import random\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create data with personal-related classes in three different languages\n",
    "\n",
    "https://faker.readthedocs.io/en/stable/providers.html   \n",
    "https://faker.readthedocs.io/en/stable/communityproviders.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'job': 'Management consultant',\n",
       " 'company': 'Humphrey-Bradford',\n",
       " 'ssn': '423-98-3062',\n",
       " 'residence': '71555 Matthew Walk Apt. 365\\nPort Nicolemouth, MP 86774',\n",
       " 'current_location': (Decimal('-19.343395'), Decimal('164.036090')),\n",
       " 'blood_group': 'O+',\n",
       " 'website': ['http://www.pollard-cannon.com/'],\n",
       " 'username': 'johntrujillo',\n",
       " 'name': 'Cody Buchanan',\n",
       " 'sex': 'M',\n",
       " 'address': '541 Robinson Circle Suite 554\\nStephanieburgh, NH 74410',\n",
       " 'mail': 'ethanwilson@yahoo.com',\n",
       " 'birthdate': datetime.date(1918, 3, 10)}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake = Faker()\n",
    "getattr(fake, 'profile')()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_attributes = [\n",
    "    \"address\", \"iban\",\"credit_card_number\", \"email\",\n",
    "    \"job\",\"first_name\",\"last_name\",\"name\",\"phone_number\",\n",
    "    \"ssn\",\"passport_number\"\n",
    "]\n",
    "\n",
    "profile_attributes = [\n",
    "    \"sex\", \"blood_group\", \"current_location\"\n",
    "]\n",
    "\n",
    "non_personal_attributes = [\n",
    "    \"color\",\"ean\",\"credit_card_provider\",\"company\",\"currency\",\n",
    "    \"url\",\"isbn13\",\"pyint\",\"pyfloat\", \"date\", \"swift\"\n",
    "]\n",
    "\n",
    "personal_attributes_unique = [\n",
    "    \"address\",\"iban\",\"credit_card_number\",\"email\",\n",
    "    \"name\",\"phone_number\", \"ssn\",\"passport_number\"\n",
    "]\n",
    "\n",
    "profile_attributes_unique = [\"current_location\"]\n",
    "\n",
    "non_personal_attributes_unique = [\n",
    "    \"color\",\"ean\", \"isbn13\", \"pyfloat\", \"swift\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "address has enough unique values:  100000\n",
      "iban has enough unique values:  100000\n",
      "credit_card_number has enough unique values:  99999\n",
      "email has enough unique values:  91461\n",
      "name has enough unique values:  98431\n",
      "phone_number has enough unique values:  100000\n",
      "ssn has enough unique values:  99996\n",
      "passport_number has enough unique values:  100000\n",
      "color has enough unique values:  89503\n",
      "ean has enough unique values:  100000\n",
      "isbn13 has enough unique values:  99974\n",
      "pyfloat has enough unique values:  100000\n",
      "swift has enough unique values:  99996\n"
     ]
    }
   ],
   "source": [
    "fake = Faker(\"de\")\n",
    "def number_unique_values(cla, profile = False):\n",
    "    val = []\n",
    "    for _ in range(100000):\n",
    "        if profile:\n",
    "            val.append(getattr(fake, \"profile\")()[cla])\n",
    "        else:\n",
    "            val.append(getattr(fake, cla)())\n",
    "    if len(set(val)) > 50000:\n",
    "        print(cla, \"has enough unique values: \", len(set(val)))\n",
    "\n",
    "for p in personal_attributes + non_personal_attributes:\n",
    "    if p == \"profile\":\n",
    "        for pp in profile_attributes:\n",
    "            number_unique_values(pp, profile = True)\n",
    "    else:\n",
    "        number_unique_values(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Faker.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "FAKE_EN = Faker(\"en\")\n",
    "FAKE_FR = Faker(\"fr_FR\")\n",
    "FAKE_DE = Faker(\"de_DE\")\n",
    "\n",
    "\n",
    "def generate_data(classes, num_col, personal_type, df, original_class, personal):\n",
    "    for cla in classes:\n",
    "        if cla in profile_attributes:\n",
    "            Faker.seed(42)\n",
    "            f1 = Faker(\"en\")\n",
    "            val1 = getattr(f1, \"profile\")()[cla]\n",
    "            Faker.seed(42)\n",
    "            f2 = Faker(\"fr_FR\")\n",
    "            val2 = getattr(f2, \"profile\")()[cla]\n",
    "        else:\n",
    "            Faker.seed(42)\n",
    "            f1 = Faker(\"en\")\n",
    "            val1 = getattr(f1, cla)()\n",
    "            Faker.seed(42)\n",
    "            f2 = Faker(\"fr_FR\")\n",
    "            val2 = getattr(f2, cla)()\n",
    "        if val1 == val2:\n",
    "            fake = FAKE_EN\n",
    "            for lan in [\"en\",\"fr_FR\",\"de_DE\", \"mixed\"]:\n",
    "                for i in range(1,num_col):                           \n",
    "                    data = {\n",
    "                            f\"{cla}_{lan}_{i}\": [],\n",
    "                        }\n",
    "                    for _ in range(100):\n",
    "                        if cla in profile_attributes:\n",
    "                            data[f\"{cla}_{lan}_{i}\"].append(getattr(fake, \"profile\")()[cla])\n",
    "                        else:\n",
    "                            data[f\"{cla}_{lan}_{i}\"].append(getattr(fake, cla)())\n",
    "                    personal_type.append(personal)\n",
    "                    original_class.append(f\"{cla}_{lan}\")\n",
    "                    df = pd.concat([df, pd.DataFrame(data)], axis=1)\n",
    "        else:\n",
    "            for (fake, lan) in zip([FAKE_EN, FAKE_FR, FAKE_DE], [\"en\",\"fr_FR\",\"de_DE\"]):\n",
    "                for i in range(1,num_col):                           \n",
    "                    data = {\n",
    "                            f\"{cla}_{lan}_{i}\": [],\n",
    "                        }\n",
    "                    for _ in range(100):\n",
    "                        if cla in profile_attributes:\n",
    "                            data[f\"{cla}_{lan}_{i}\"].append(getattr(fake, \"profile\")()[cla])\n",
    "                        else:\n",
    "                            data[f\"{cla}_{lan}_{i}\"].append(getattr(fake, cla)())\n",
    "                    personal_type.append(personal)\n",
    "                    original_class.append(f\"{cla}_{lan}\")\n",
    "                    df = pd.concat([df, pd.DataFrame(data)], axis=1)\n",
    "            for i in range(1,num_col):                           \n",
    "                data = {\n",
    "                        f\"{cla}_mixed_{i}\": [],\n",
    "                    }\n",
    "                for (fake, lan) in zip([FAKE_EN, FAKE_FR, FAKE_DE],[\"en\",\"fr_FR\",\"de_DE\"]):\n",
    "                    for _ in range(33 if lan != \"en\" else 34):\n",
    "                        if cla in profile_attributes:\n",
    "                            data[f\"{cla}_mixed_{i}\"].append(getattr(fake, \"profile\")()[cla])\n",
    "                        else:\n",
    "                            data[f\"{cla}_mixed_{i}\"].append(getattr(fake, cla)())\n",
    "                personal_type.append(personal)\n",
    "                original_class.append(f\"{cla}_mixed\")\n",
    "                df = pd.concat([df, pd.DataFrame(data)], axis=1)\n",
    "    return personal_type, df, original_class\n",
    "  \n",
    "def generate_data_unique(classes, num_col, personal_type, df, original_class, personal):\n",
    "    mixed_data = dict()\n",
    "    for cla in classes:\n",
    "        if cla in profile_attributes_unique:\n",
    "            Faker.seed(42)\n",
    "            f1 = Faker(\"en\")\n",
    "            val1 = getattr(f1, \"profile\")()[cla]\n",
    "            Faker.seed(42)\n",
    "            f2 = Faker(\"fr_FR\")\n",
    "            val2 = getattr(f2, \"profile\")()[cla]\n",
    "        else:\n",
    "            Faker.seed(42)\n",
    "            f1 = Faker(\"en\")\n",
    "            val1 = getattr(f1, cla)()\n",
    "            Faker.seed(42)\n",
    "            f2 = Faker(\"fr_FR\")\n",
    "            val2 = getattr(f2, cla)()\n",
    "        if val1 == val2:\n",
    "            values = set()\n",
    "            num_generate = (num_col *4.5)\n",
    "            while len(values) < num_generate*100:\n",
    "                if cla not in profile_attributes_unique:\n",
    "                    values.add(getattr(f1, cla)())\n",
    "                else:\n",
    "                    values.add(getattr(f1, \"profile\")()[cla])\n",
    "            values = sorted(values)\n",
    "            random.shuffle(values)\n",
    "            for lan in [\"en\",\"fr_FR\",\"de_DE\", \"mixed\"]:\n",
    "                for i in range(1,num_col):                           \n",
    "                    data = {\n",
    "                            f\"{cla}_{lan}_{i}\": [],\n",
    "                        }\n",
    "                    popped_elements = values[:100]\n",
    "                    values = values[100:]\n",
    "                    data[f\"{cla}_{lan}_{i}\"] = popped_elements\n",
    "                    personal_type.append(personal)\n",
    "                    original_class.append(f\"{cla}_{lan}\")\n",
    "                    df = pd.concat([df, pd.DataFrame(data)], axis=1)\n",
    "        else:\n",
    "            all_values = set()\n",
    "            for (fake, lan) in zip([FAKE_EN, FAKE_FR, FAKE_DE], [\"en\",\"fr_FR\",\"de_DE\"]):\n",
    "                values = set()\n",
    "                num_generate = (num_col *1.5)\n",
    "                while len(values) < num_generate*100:\n",
    "                    if cla not in profile_attributes_unique:\n",
    "                        adding_val = getattr(fake, cla)()\n",
    "                        if adding_val not in all_values:\n",
    "                            values.add(adding_val)\n",
    "                    else:\n",
    "                        adding_val = getattr(fake, \"profile\")()[cla]\n",
    "                        if adding_val not in all_values:\n",
    "                            values.add(adding_val)\n",
    "                values = sorted(values)\n",
    "                random.shuffle(values)\n",
    "                all_values = all_values.union(set(values))\n",
    "                for i in range(1,num_col):                           \n",
    "                    data = {\n",
    "                            f\"{cla}_{lan}_{i}\": [],\n",
    "                        }\n",
    "                    popped_elements = values[:100]\n",
    "                    values = values[100:]\n",
    "                    data[f\"{cla}_{lan}_{i}\"] = popped_elements\n",
    "                    personal_type.append(personal)\n",
    "                    original_class.append(f\"{cla}_{lan}\")\n",
    "                    df = pd.concat([df, pd.DataFrame(data)], axis=1)\n",
    "                mixed_data[f'{lan}_{cla}'] = values\n",
    "            for i in range(1,num_col):                           \n",
    "                    data = {\n",
    "                            f\"{cla}_mixed_{i}\": [],\n",
    "                        }\n",
    "                    for lan in [\"en\",\"fr_FR\",\"de_DE\"]:\n",
    "                        if lan == \"en\":\n",
    "                            num=34\n",
    "                        else:\n",
    "                            num=33\n",
    "                        for v in mixed_data[f'{lan}_{cla}'][num*(i-1):num*(i-1)+num]:\n",
    "                            data[f\"{cla}_mixed_{i}\"].append(v)\n",
    "                    personal_type.append(personal)\n",
    "                    original_class.append(f\"{cla}_mixed\")\n",
    "                    df = pd.concat([df, pd.DataFrame(data)], axis=1)\n",
    "    return personal_type, df, original_class\n",
    "    \n",
    "    \n",
    "def generate_random_string(length):\n",
    "    # Define the characters to use (letters and digits)\n",
    "    characters = string.ascii_letters + string.digits\n",
    "    return ''.join(random.choice(characters) for _ in range(length))\n",
    "\n",
    "def extract_label(df):\n",
    "    df_labels = df.iloc[100,:]\n",
    "    df_classes = df.iloc[101,:]\n",
    "    df = df.iloc[:100,:]\n",
    "    df_labels = pd.DataFrame(df_labels)\n",
    "    df_classes = pd.DataFrame(df_classes)\n",
    "    df_labels = df_labels.rename(columns={df_labels.columns[0]: \"label\"}).reset_index(drop=True)\n",
    "    df_classes = df_classes.rename(columns={df_classes.columns[0]: \"class\"}).reset_index(drop=True)\n",
    "    return df, df_labels, df_classes\n",
    "\n",
    "  \n",
    "def rename_columns(df, num_personal, num_non_personal):\n",
    "    for attributes in [personal_attributes, non_personal_attributes, profile_attributes]:\n",
    "        for p in attributes:\n",
    "            if attributes == personal_attributes or attributes == profile_attributes:\n",
    "                num_col = num_personal\n",
    "            else:\n",
    "                num_col = num_non_personal\n",
    "            for lan in [\"en\",\"fr_FR\",\"de_DE\", \"mixed\"]:\n",
    "                for i in range(1,num_col, 2):\n",
    "                    random_length = random.randint(5, 20)\n",
    "                    random_string = generate_random_string(random_length)\n",
    "                    df.rename(columns={f\"{p}_{lan}_{i}\": random_string}, inplace=True)\n",
    "            for i in range(1, num_col, 2):\n",
    "                random_length = random.randint(5, 20)\n",
    "                random_string = generate_random_string(random_length)\n",
    "                df.rename(columns={f\"mixed_{p}_{i}\": random_string}, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_dataset():\n",
    "    personal_type = []\n",
    "    original_class = []\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    personal_type, df, original_class = generate_data(set(personal_attributes + profile_attributes) - set(personal_attributes_unique + profile_attributes_unique), 286, personal_type, df, original_class, \"personal\")\n",
    "    personal_type, df, original_class = generate_data(set(non_personal_attributes) - set(non_personal_attributes_unique), 364, personal_type, df, original_class, \"non-personal\")\n",
    "\n",
    "    # generate columns were only unique values are possible\n",
    "    personal_type, df, original_class = generate_data_unique(personal_attributes_unique + profile_attributes_unique, \n",
    "                                                      286, personal_type, df, original_class, \"personal\")\n",
    "    personal_type, df, original_class = generate_data_unique(non_personal_attributes_unique,\n",
    "                                                      364, personal_type, df, original_class, \"non-personal\")\n",
    "    \n",
    "    df = rename_columns(df, 286, 364)\n",
    "\n",
    "    #shuffle the columns\n",
    "    labels = pd.DataFrame(personal_type).T\n",
    "    classes = pd.DataFrame(original_class).T\n",
    "    labels.columns = df.columns\n",
    "    classes.columns = df.columns\n",
    "    df = pd.concat([df, labels]).reset_index(drop=True)\n",
    "    df = pd.concat([df, classes]).reset_index(drop=True)\n",
    "    df = df.sample(frac=1, axis=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    #save the data\n",
    "    df_final, labels, classes = extract_label(df)\n",
    "    df_final.to_csv(\"all.csv\", index=False)\n",
    "    labels.to_csv(\"all_labels.csv\", index=False)\n",
    "    classes.to_csv(\"all_classes.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "285.7142857142857"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16000 / (len(personal_attributes) + len(profile_attributes))/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "363.6363636363636"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16000 / len(non_personal_attributes) /4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/Val/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luca\\AppData\\Local\\Temp\\ipykernel_5812\\1934159018.py:1: DtypeWarning: Columns (15,104,268,301,349,359,436,573,690,748,784,935,951,1004,1144,1237,1289,1549,1644,1725,1864,1977,2039,2155,2216,2331,2388,2440,2488,2616,2657,2736,2758,2769,2902,2916,3189,3264,3277,3332,3425,3433,3483,3599,3640,3641,3676,3746,3777,3882,3960,4009,4026,4080,4110,4113,4165,4213,4216,4244,4270,4293,4318,4340,4374,4678,4788,4792,4876,4931,4943,5055,5210,5380,5564,5584,5778,5810,5922,5975,6041,6160,6265,6341,6688,6720,6742,6817,6823,6866,6872,6995,7076,7091,7119,7266,7393,7446,7533,7604,7643,7936,7962,7966,8132,8260,8428,8563,8567,8670,8683,8734,8779,8812,8867,8875,8997,9002,9145,9188,9290,9334,9604,9812,9926,9929,9942,9956,10097,10111,10214,10277,10288,10368,10390,10435,10458,10577,10718,10894,10918,10937,11037,11075,11077,11244,11248,11299,11343,11379,11595,11622,11745,11823,12121,12292,12575,12638,12675,12712,12735,12850,12884,12987,13254,13357,13394,13579,13610,13620,13639,13647,13739,13740,13754,13891,14152,14285,14307,14330,14340,14496,14520,14538,14655,14696,14778,14787,14870,14929,15040,15054,15141,15206,15260,15264,15366,15391,15423,15447,15549,15564,15575,15714,15811,15882,15916,15925,16432,16513,16571,16580,16712,16789,16827,16892,16899,17031,17118,17223,17473,17648,17701,17717,17808,18057,18088,18339,18397,18516,18729,18747,18767,18842,19041,19186,19344,19535,19650,19682,19756,19760,19848,19860,19872,19883,20010,20115,20191,20215,20251,20442,20599,20698,20699,20837,20906,20944,21041,21145,21154,21174,21242,21416,21484,21568,21584,21958,21990,22010,22081,22119,22290,22352,22443,22498,22613,22718,22891,22949,23199,23237,23249,23311,23364,24005,24010,24079,24085,24122,24326,24466,24590,24848,24875,24940,25018,25061,25167,25437,25592,25794,25802,25875,26038,26091,26104,26210,26289,26500,26520,26680,26727,26799,26876,26881,26897,27166,27204,27241,27272,27368,27694,27729,27951,28122,28201,28452,28535,28669,28692,28766,28768,28844,29081,29202,29308,29352,29358,29993,30056,30084,30137,30157,30184,30249,30331,30476,30483,30617,30733,30812,31156,31204,31225,31380,31385,31433,31600,31683,31714,31720,31742,31923) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_all = pd.read_csv(\"faker/all.csv\")\n"
     ]
    }
   ],
   "source": [
    "df_all = pd.read_csv(\"all.csv\")\n",
    "df_all_labels = pd.read_csv(\"all_labels.csv\")\n",
    "df_all_classes = pd.read_csv(\"all_classes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (100, 19159)\n",
      "Validation data shape: (100, 6386)\n",
      "Test data shape: (100, 6387)\n"
     ]
    }
   ],
   "source": [
    "split1 = StratifiedShuffleSplit(n_splits=1, test_size=0.4, random_state=42)\n",
    "train_idx, temp_idx = next(split1.split(df_all.T, df_all_classes[\"class\"]))\n",
    "train_data = df_all.iloc[:, train_idx]\n",
    "train_classes = df_all_classes.T[train_idx].T\n",
    "train_labels = df_all_labels.T[train_idx].T\n",
    "temp_data = df_all.iloc[:, temp_idx]  \n",
    "temp_classes = df_all_classes.T[temp_idx].T\n",
    "temp_labels = df_all_labels.T[temp_idx].T\n",
    "\n",
    "split2 = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=42)\n",
    "val_idx, test_idx = next(split2.split(temp_data.T, temp_classes))\n",
    "\n",
    "val_data = temp_data.iloc[:, val_idx]\n",
    "val_classes = temp_classes.T.iloc[:,val_idx].T\n",
    "val_labels = temp_labels.T.iloc[:,val_idx].T\n",
    "test_data = temp_data.iloc[:, test_idx]\n",
    "test_classes = temp_classes.T.iloc[:,test_idx].T\n",
    "test_labels = temp_labels.T.iloc[:,test_idx].T\n",
    "\n",
    "\n",
    "print(\"Train data shape:\", train_data.shape)\n",
    "print(\"Validation data shape:\", val_data.shape)\n",
    "print(\"Test data shape:\", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv(\"train.csv\", index=False)\n",
    "train_labels.to_csv(\"train_labels.csv\", index=False)\n",
    "train_classes.to_csv(\"train_classes.csv\", index=False)\n",
    "\n",
    "val_data.to_csv(\"dev.csv\", index=False)\n",
    "val_labels.to_csv(\"dev_labels.csv\", index=False)\n",
    "val_classes.to_csv(\"dev_classes.csv\", index=False)\n",
    "\n",
    "test_data.to_csv(\"test.csv\", index=False)\n",
    "test_labels.to_csv(\"test_labels.csv\", index=False)\n",
    "test_classes.to_csv(\"test_classes.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "presidio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
