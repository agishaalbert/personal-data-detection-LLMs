{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect datasets based on real-world data, that are personal related  \n",
    "Search for specific personal-related categories (credit-card, insurance ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate the Kaggle API, an token is needed!\n",
    "api = KaggleApi()\n",
    "api.authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_dataset(link, path):\n",
    "    api.dataset_download_files(link, path=path, unzip=True)\n",
    "    api.dataset_metadata(link, path=path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple options to filter/search after datasets, look up in kaggle docs, same filter options as in web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/kewagbln/absenteeism-at-work-uci-ml-repositiory\n",
      "Dataset URL: https://www.kaggle.com/datasets/yasserh/titanic-dataset\n",
      "Dataset URL: https://www.kaggle.com/datasets/mohansacharya/graduate-admissions\n",
      "Dataset URL: https://www.kaggle.com/datasets/redwankarimsony/heart-disease-data\n",
      "Dataset URL: https://www.kaggle.com/datasets/naserabdullahalam/phishing-email-dataset\n",
      "Dataset URL: https://www.kaggle.com/datasets/priyamchoksi/adult-census-income-dataset\n",
      "Dataset URL: https://www.kaggle.com/datasets/volodymyrgavrysh/bank-marketing-campaigns-dataset\n",
      "Dataset URL: https://www.kaggle.com/datasets/dskagglemt/student-performance-data-set\n",
      "Dataset URL: https://www.kaggle.com/datasets/alakaaay/diabetes-uci-dataset\n",
      "Dataset URL: https://www.kaggle.com/datasets/uciml/indian-liver-patient-records\n",
      "Dataset URL: https://www.kaggle.com/datasets/rummagelabs/pixar-movies\n",
      "Dataset URL: https://www.kaggle.com/datasets/jakewright/house-price-data\n",
      "Dataset URL: https://www.kaggle.com/datasets/rowhitswami/all-indian-companies-registration-data-1900-2019\n",
      "Dataset URL: https://www.kaggle.com/datasets/imtkaggleteam/agriculture-dataset-karnataka\n",
      "Dataset URL: https://www.kaggle.com/datasets/mohitkumar282/used-car-dataset\n"
     ]
    }
   ],
   "source": [
    "# 5 Datasets with PII Information in single columns\n",
    "download_dataset(\"kewagbln/absenteeism-at-work-uci-ml-repositiory\", \"absenteeism/\")\n",
    "download_dataset('yasserh/titanic-dataset','titanic/')\n",
    "download_dataset(\"mohansacharya/graduate-admissions\", \"graduate_admissions/\")\n",
    "os.remove(\"graduate_admissions/Admission_Predict_Ver1.1.csv\")\n",
    "download_dataset(\"redwankarimsony/heart-disease-data\", \"heart_disease/\")\n",
    "download_dataset(\"naserabdullahalam/phishing-email-dataset\", \"phishing_email/\")\n",
    "os.remove(\"phishing_email/Enron.csv\")\n",
    "os.remove(\"phishing_email/Ling.csv\")\n",
    "os.remove(\"phishing_email/Nazario.csv\")\n",
    "os.remove(\"phishing_email/Nigerian_Fraud.csv\")\n",
    "os.remove(\"phishing_email/SpamAssasin.csv\")\n",
    "os.remove(\"phishing_email/phishing_email.csv\")\n",
    "\n",
    "# 5 Datasets without PII Information in single columns but the whole dataset contains PII as combined information\n",
    "download_dataset(\"priyamchoksi/adult-census-income-dataset\", \"adult_census/\")\n",
    "download_dataset(\"volodymyrgavrysh/bank-marketing-campaigns-dataset\", \"bank_marketing/\")\n",
    "download_dataset(\"dskagglemt/student-performance-data-set\", \"student_performance/\")\n",
    "os.remove(\"student_performance/student-por.csv\")\n",
    "download_dataset(\"alakaaay/diabetes-uci-dataset\", \"diabetes/\")\n",
    "download_dataset(\"uciml/indian-liver-patient-records\", \"indian_liver/\")\n",
    "\n",
    "# 5 Datasets without PII Information in single columns and the whole dataset does not contain PII in combination\n",
    "download_dataset(\"rummagelabs/pixar-movies\", \"pixar/\")\n",
    "download_dataset(\"jakewright/house-price-data\", \"house_price/\")\n",
    "download_dataset(\"rowhitswami/all-indian-companies-registration-data-1900-2019\", \"indian_companies/\")\n",
    "download_dataset(\"imtkaggleteam/agriculture-dataset-karnataka\", \"agriculture/\")\n",
    "download_dataset(\"mohitkumar282/used-car-dataset\", \"used_car/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Personal "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "automatically label the column as personal-related if it is from the first ten datasets       \n",
    "Personal-related is in this context data that can be used in combination with other data to identify a person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luca\\AppData\\Local\\Temp\\ipykernel_27156\\2754824976.py:14: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path + \"/\" + csv_file, sep=sep)\n"
     ]
    }
   ],
   "source": [
    "def create_json_labels_personal():\n",
    "    folders = [name for name in os.listdir(\".\") if os.path.isdir(os.path.join(\".\", name))]\n",
    "    for folder in folders:\n",
    "        path = folder\n",
    "        csv_file = [f for f in os.listdir(path) if f.endswith('.csv') and 'labels' not in f][0]\n",
    "        with open(path + \"/\" + csv_file, 'r') as file:\n",
    "            first_line = file.readline()\n",
    "            comma_count = first_line.count(',')\n",
    "            semicolon_count = first_line.count(';')\n",
    "            if comma_count > semicolon_count:\n",
    "                sep = \",\"\n",
    "            else:\n",
    "                sep = \";\"\n",
    "        df = pd.read_csv(path + \"/\" + csv_file, sep=sep)\n",
    "        columns_personal = dict()\n",
    "        if any(a in folder for a in [\"pixar\", \"house_price\", \"indian_companies\", \"auto_sales\", \"graduate_admissions\"]):\n",
    "            lab = \"non-personal\"\n",
    "        else:\n",
    "            lab = \"personal\"\n",
    "        for c in df.columns:\n",
    "            columns_personal[c] = lab\n",
    "        columns_personal[\"overall\"] = lab\n",
    "        with open(f'{folder}/{csv_file}-labels_personal.json', 'w') as file:\n",
    "            json.dump(columns_personal, file, indent=4)\n",
    "\n",
    "#line to execute function is commented so that it is not always executed, labeling process only happens once\n",
    "#create_json_labels_personal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SOME LABELS WERE ADJUSTED MANUALLY AFTERWARDS IN THE JSON FILES**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the labels into a suitable csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = [name for name in os.listdir(\".\") if os.path.isdir(os.path.join(\".\", name))]\n",
    "for folder in folders:\n",
    "    path_folder = folder\n",
    "    csv_file = [f for f in os.listdir(path_folder) if f.endswith('.csv') and 'labels' not in f][0]\n",
    "    path = path_folder + \"/\" + csv_file + \"-labels_personal.json\"\n",
    "    with open(path, 'r') as file:\n",
    "        labels_json = json.load(file)\n",
    "    pd.DataFrame(labels_json, index=[0]).T.rename(columns={0: \"label\"}).to_csv(path_folder + \"/labels_personal.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate all datasets and labels for CASSED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luca\\AppData\\Local\\Temp\\ipykernel_17556\\4134643317.py:18: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_add = pd.read_csv(path_folder + \"/\" + csv_file, sep=sep)\n"
     ]
    }
   ],
   "source": [
    "folders = [name for name in os.listdir(\".\") if os.path.isdir(os.path.join(\".\", name))]\n",
    "all_dfs = pd.DataFrame()\n",
    "all_dfs_labels = pd.DataFrame()\n",
    "dataset_name = []\n",
    "for folder in folders:\n",
    "    path_folder = folder\n",
    "    csv_file = [f for f in os.listdir(path_folder) if f.endswith('.csv') and 'labels' not in f][0]\n",
    "    csv_file_label = [f for f in os.listdir(path_folder) if f.endswith('.csv') and 'labels_personal' in f][0]\n",
    "    \n",
    "    with open(path_folder + \"/\" + csv_file, 'r') as file:\n",
    "        first_line = file.readline()\n",
    "        comma_count = first_line.count(',')\n",
    "        semicolon_count = first_line.count(';')\n",
    "        if comma_count > semicolon_count:\n",
    "            sep = \",\"\n",
    "        else:\n",
    "            sep = \";\"\n",
    "    df_add = pd.read_csv(path_folder + \"/\" + csv_file, sep=sep)\n",
    "    \n",
    "    all_dfs = pd.concat([all_dfs, df_add.iloc[:100,:]], axis = 1)\n",
    "    add_dfs_labels = pd.read_csv(path_folder + \"/\" + csv_file_label)\n",
    "    all_dfs_labels = pd.concat([all_dfs_labels, add_dfs_labels.iloc[:-1]]).reset_index(drop=True)\n",
    "    dataset_name += [folder] * df_add.shape[1]\n",
    "all_dfs.to_csv(\"all_datasets.csv\", index=False)\n",
    "all_dfs_labels.to_csv(\"all_datasets_labels_personal.csv\", index=False)\n",
    "pd.DataFrame(dataset_name).rename(columns={0: \"dataset\"}).to_csv(\"all_datasets_names.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PII"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "automatically label the column as pii if it only contains unique values  \n",
    "Afterwards look trough all .json files and check the column labeling      \n",
    "only columns which can contain personal identifiable information without a combination with other information are marked as pii "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_json_labels_pii():\n",
    "    folders = [name for name in os.listdir(\".\") if os.path.isdir(os.path.join(\".\", name))]\n",
    "    for folder in folders:\n",
    "        path = folder\n",
    "        csv_file = [f for f in os.listdir(path) if f.endswith('.csv') and 'labels' not in f][0]\n",
    "        with open(path + \"/\" + csv_file, 'r') as file:\n",
    "            first_line = file.readline()\n",
    "            comma_count = first_line.count(',')\n",
    "            semicolon_count = first_line.count(';')\n",
    "            if comma_count > semicolon_count:\n",
    "                sep = \",\"\n",
    "            else:\n",
    "                sep = \";\"\n",
    "        df = pd.read_csv(path + \"/\" + csv_file, sep=sep)\n",
    "        columns_personal = dict()\n",
    "        for c in df.columns:\n",
    "            columns_personal[c] = \"non-pii\"\n",
    "        columns_personal[\"overall\"] = \"pii\"\n",
    "        with open(f'{folder}/{csv_file}-labels_pii.json', 'w') as file:\n",
    "            json.dump(columns_personal, file, indent=4)\n",
    "            \n",
    "#line to execute function is commented so that it is not always executed, labeling process only happens once\n",
    "#create_json_labels_pii()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SOME LABELS WERE ADJUSTED MANUALLY AFTERWARDS IN THE JSON FILES**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the labels into a suitable csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = [name for name in os.listdir(\".\") if os.path.isdir(os.path.join(\".\", name))]\n",
    "for folder in folders:\n",
    "    path_folder = folder\n",
    "    csv_file = [f for f in os.listdir(path_folder) if f.endswith('.csv') and 'labels' not in f][0]\n",
    "    path = path_folder + \"/\" + csv_file + \"-labels_pii.json\"\n",
    "    with open(path, 'r') as file:\n",
    "        labels_json = json.load(file)\n",
    "    pd.DataFrame(labels_json, index=[0]).T.rename(columns={0: \"label\"}).to_csv(path_folder + \"/labels_pii.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate all datasets and labels for CASSED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luca\\AppData\\Local\\Temp\\ipykernel_17556\\321388133.py:17: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_add = pd.read_csv(path_folder + \"/\" + csv_file, sep=sep)\n"
     ]
    }
   ],
   "source": [
    "folders = [name for name in os.listdir(\".\") if os.path.isdir(os.path.join(\".\", name))]\n",
    "all_dfs = pd.DataFrame()\n",
    "all_dfs_labels = pd.DataFrame()\n",
    "for folder in folders:\n",
    "    path_folder = folder\n",
    "    csv_file = [f for f in os.listdir(path_folder) if f.endswith('.csv') and 'labels' not in f][0]\n",
    "    csv_file_label = [f for f in os.listdir(path_folder) if f.endswith('.csv') and 'labels_pii' in f][0]\n",
    "    \n",
    "    with open(path_folder + \"/\" + csv_file, 'r') as file:\n",
    "        first_line = file.readline()\n",
    "        comma_count = first_line.count(',')\n",
    "        semicolon_count = first_line.count(';')\n",
    "        if comma_count > semicolon_count:\n",
    "            sep = \",\"\n",
    "        else:\n",
    "            sep = \";\"\n",
    "    df_add = pd.read_csv(path_folder + \"/\" + csv_file, sep=sep)\n",
    "    \n",
    "    all_dfs = pd.concat([all_dfs, df_add.iloc[:100,:]], axis = 1)\n",
    "    add_dfs_labels = pd.read_csv(path_folder + \"/\" + csv_file_label)\n",
    "    all_dfs_labels = pd.concat([all_dfs_labels, add_dfs_labels.iloc[:-1]]).reset_index(drop=True)\n",
    "all_dfs.to_csv(\"all_datasets.csv\", index=False)\n",
    "all_dfs_labels.to_csv(\"all_datasets_labels_pii.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
